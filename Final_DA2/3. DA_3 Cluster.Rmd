---
title: "3. DA_Cluster"
author: "Xin Tan, 583833"
date: "2019/3/11"
output:
  html_document:
    df_print: paged
---



In the cluster, NA means the respondents have no experence about the rating objective, which should not be imputate with another number, otherwise we will lose this important information. Here I will replace the NA with zero, on the  one hand, the information has been kept, on the other hand, the orienginal scale and the distribution of data is not influenced too much.

```{r}

# prepare for the attribute table
dat <- read_excel("Data_Chocolate_allinterviews.xlsx", sheet = "AttributeRatingsStacked")
dat<-as.data.frame(dat)

attribute.rating<- aggregate(dat[,-c(1,2)], by=list(dat$Person),mean, na.rm=F)
attribute.rating[is.na(attribute.rating)] <- 0
colnames(attribute.rating)[1] <- "Person"

```





# Cluster only use attribute
```{r}

H-cluster
library(cluster)
d <- dist(attribute.rating[-c(1)])
tmp.cluster <-hclust(dist.df, method = "ward.D2") 

{plot(as.dendrogram(tmp.cluster),main = "Ward Cluster Dendrogram", horiz = FALSE)
rect.hclust(tmp.cluster , k = 3, border = "red")}




# Silhouette of H-cluster (2 clusters is better)
cl1  <- hclust(d, method="ward.D2")
memb2 <- cutree(cl1, 2)
memb3 <- cutree(cl1, 3)
#
library("cluster")
par(mfcol=c(2,2))
plot(attribute.rating, col=memb2)
s2 <- silhouette(memb2, d)
plot(s2, col=1:2, border=NA)
plot(attribute.rating, col=memb3)
s3 <- silhouette(memb3, d)
plot(s3, col=1:3, border=NA)




# h-cluster visualization
cl1  <- hclust(d, method="ward.D2")
memb2 <- cutree(cl1, 2)
memb3 <- cutree(cl1, 3)
#
library("cluster")
par(mfcol=c(1,2))
clusplot(attribute.rating, memb2, col.p=memb2)
clusplot(attribute.rating, memb3, col.p=memb3)


# Calinski and Harabasz (suggest 2 cluster)
NbClust(attribute.rating[-1], method="ward.D2", index="ch")




library("cluster")
library("mlbench") # for Boston Housing data

# prepare data


# Diana (好像没什么用)
cl  <- diana(attribute.rating[-c(1)])
hcl <- cutree(as.hclust(cl), k = 3)
par(mfrow=c(4,4))
plot(attribute.rating$Person, attribute.rating$crunchy, col=hcl, pch=19, cex=0.5)
plot(attribute.rating$Person, attribute.rating$creamy, col=hcl, pch=19, cex=0.5)
plot(attribute.rating$Person, attribute.rating$sweet, col=hcl, pch=19, cex=0.5)
plot(attribute.rating$Person, attribute.rating$chocolaty, col=hcl, pch=19, cex=0.5)
plot(attribute.rating$Person, attribute.rating$healthful, col=hcl, pch=19, cex=0.5)
plot(attribute.rating$Person, attribute.rating$calorie, col=hcl, pch=19, cex=0.5)
plot(attribute.rating$Person, attribute.rating$rich, col=hcl, pch=19, cex=0.5)
plot(attribute.rating$Person, attribute.rating$addiction, col=hcl, pch=19, cex=0.5)
plot(attribute.rating$Person, attribute.rating$accessible, col=hcl, pch=19, cex=0.5)
plot(attribute.rating$Person, attribute.rating$handy, col=hcl, pch=19, cex=0.5)
plot(attribute.rating$Person, attribute.rating$wrapping, col=hcl, pch=19, cex=0.5)
plot(attribute.rating$Person, attribute.rating$image, col=hcl, pch=19, cex=0.5)
plot(attribute.rating$Person, attribute.rating$commercial, col=hcl, pch=19, cex=0.5)






# -------------------------------- kmeans
library(cluster)

# Calinski and Harabasz (suggest 2 cluster)
NbClust(attribute.rating[-1], method="kmeans", index="ch")

set.seed(4)
seg.k <- kmeans(attribute.rating[-c(1)] , centers= 3)

attribute.rating$kmeans <- seg.k$cluster
clusplot(attribute.rating[-c(1)], seg.k$cluster, color=TRUE, shade=TRUE,labels= , lines=0, main="K-means cluster")


table(seg.k$cluster)
table(seg.k$cluster)/50




# fit statistics
seg.k$betweenss
seg.k$totss
seg.k$betweenss/seg.k$totss



# kmeans Silhouette

library("cluster")
d <- dist(attribute.rating[-c(1)])
set.seed(4)
seg.k <- kmeans(attribute.rating[-c(1)] , centers= 2)
seg.k 
memb2 <- seg.k$cluster

s2 <- silhouette(memb2, d)
plot(s2, col=1:2, border=NA)


```


## remove the respondents with 0 rating
```{r}
attribute.rating<-attribute.rating[!(attribute.rating$kmeans==3),]
```




# 不行
```{r}

# k-median
library("flexclust")
cl1 <- kcca(cluster.df, 2, family=kccaFamily('kmedians'))
plot(cluster.df, col=cl1@second)
cl1@centers
# k-medoid
library("cluster")
cl2 <- pam(cluster.df, 3)
plot(cluster.df, col=cl2$clustering)
cl2$medoids



```






